{"uuid": "816cabcb-909d-4d72-94a1-8675277920fc", "provider": "UNKNOWN", "num_cpu": 192, "cpu_type": "Intel(R) Xeon(R) Platinum 8474C", "cpu_family_model_stepping": "6,143,8", "total_memory": 1081835008000, "architecture": "x86_64", "platform": "Linux-5.15.0-94-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA GeForce RTX 4090 D", "gpu_memory_per_device": 25386352640, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": \"XFORMERS\", \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": false, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.8.2", "context": "LLM_CLASS", "log_time": 1747566177405425920, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 1, "block_size": 16, "gpu_memory_utilization": 0.7, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": true, "disable_custom_all_reduce": true}
{"uuid": "5d5613fb-1011-420f-a4cd-61fd9df66358", "provider": "UNKNOWN", "num_cpu": 192, "cpu_type": "Intel(R) Xeon(R) Platinum 8474C", "cpu_family_model_stepping": "6,143,8", "total_memory": 1081835008000, "architecture": "x86_64", "platform": "Linux-5.15.0-94-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA GeForce RTX 4090 D", "gpu_memory_per_device": 25386352640, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": \"XFORMERS\", \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": false, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.8.2", "context": "LLM_CLASS", "log_time": 1747566178223858176, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 1, "block_size": 16, "gpu_memory_utilization": 0.7, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": true, "disable_custom_all_reduce": true}
{"uuid": "b666ecc4-6dcb-46ee-89fc-c64ebe553731", "provider": "UNKNOWN", "num_cpu": 192, "cpu_type": "Intel(R) Xeon(R) Platinum 8474C", "cpu_family_model_stepping": "6,143,8", "total_memory": 1081835008000, "architecture": "x86_64", "platform": "Linux-5.15.0-94-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA GeForce RTX 4090 D", "gpu_memory_per_device": 25386352640, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": \"XFORMERS\", \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": false, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.8.2", "context": "LLM_CLASS", "log_time": 1747566178225783040, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 1, "block_size": 16, "gpu_memory_utilization": 0.7, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": true, "disable_custom_all_reduce": true}
{"uuid": "53a46de8-297d-467e-9a09-8a3421d75100", "provider": "UNKNOWN", "num_cpu": 192, "cpu_type": "Intel(R) Xeon(R) Platinum 8474C", "cpu_family_model_stepping": "6,143,8", "total_memory": 1081835008000, "architecture": "x86_64", "platform": "Linux-5.15.0-94-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA GeForce RTX 4090 D", "gpu_memory_per_device": 25386352640, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": \"XFORMERS\", \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": false, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.8.2", "context": "LLM_CLASS", "log_time": 1747566178394344192, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 1, "block_size": 16, "gpu_memory_utilization": 0.7, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": true, "disable_custom_all_reduce": true}
{"uuid": "3d19aa9c-a286-4ec0-903c-bd4104bc6211", "provider": "UNKNOWN", "num_cpu": 192, "cpu_type": "Intel(R) Xeon(R) Platinum 8474C", "cpu_family_model_stepping": "6,143,8", "total_memory": 1081835008000, "architecture": "x86_64", "platform": "Linux-5.15.0-94-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA GeForce RTX 4090 D", "gpu_memory_per_device": 25386352640, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": \"XFORMERS\", \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": false, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.8.2", "context": "LLM_CLASS", "log_time": 1747566371894141952, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 1, "block_size": 16, "gpu_memory_utilization": 0.7, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": true, "disable_custom_all_reduce": true}
{"uuid": "7ddcf07a-92f3-495a-a7c9-e34fc60e1070", "provider": "UNKNOWN", "num_cpu": 192, "cpu_type": "Intel(R) Xeon(R) Platinum 8474C", "cpu_family_model_stepping": "6,143,8", "total_memory": 1081835008000, "architecture": "x86_64", "platform": "Linux-5.15.0-94-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA GeForce RTX 4090 D", "gpu_memory_per_device": 25386352640, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": \"XFORMERS\", \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": false, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.8.2", "context": "LLM_CLASS", "log_time": 1747566372108987136, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 1, "block_size": 16, "gpu_memory_utilization": 0.7, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": true, "disable_custom_all_reduce": true}
{"uuid": "9c4a8dd9-e8d1-4f0d-b1a6-d21d0b6d5bc6", "provider": "UNKNOWN", "num_cpu": 192, "cpu_type": "Intel(R) Xeon(R) Platinum 8474C", "cpu_family_model_stepping": "6,143,8", "total_memory": 1081835008000, "architecture": "x86_64", "platform": "Linux-5.15.0-94-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA GeForce RTX 4090 D", "gpu_memory_per_device": 25386352640, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": \"XFORMERS\", \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": false, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.8.2", "context": "LLM_CLASS", "log_time": 1747566372333309952, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 1, "block_size": 16, "gpu_memory_utilization": 0.7, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": true, "disable_custom_all_reduce": true}
{"uuid": "6a8508bd-0d27-4ff3-8c8b-5ce279158c83", "provider": "UNKNOWN", "num_cpu": 192, "cpu_type": "Intel(R) Xeon(R) Platinum 8474C", "cpu_family_model_stepping": "6,143,8", "total_memory": 1081835008000, "architecture": "x86_64", "platform": "Linux-5.15.0-94-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA GeForce RTX 4090 D", "gpu_memory_per_device": 25386352640, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": \"XFORMERS\", \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": false, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.8.2", "context": "LLM_CLASS", "log_time": 1747566372428961024, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 1, "block_size": 16, "gpu_memory_utilization": 0.7, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": true, "disable_custom_all_reduce": true}
